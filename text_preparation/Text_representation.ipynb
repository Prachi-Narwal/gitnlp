{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c3ed09",
   "metadata": {},
   "source": [
    "## 1. N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1030b37",
   "metadata": {},
   "source": [
    "#### 1.1. Bag of words (BOW) -> Uni-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ca2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#importing the pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799281b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame({'text':['people watch campusx','campusx watch campusx','people write comment','campusx write comment'],'output':[1,1,0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80d7cf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4df3724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9746a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow=cv.fit_transform(df1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f277b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n"
     ]
    }
   ],
   "source": [
    "#vocab in alphabatetical order\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b482c740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 0]]\n",
      "[[2 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())\n",
    "print(bow[1].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df27199b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(['campusx watch and write comment of campusx']).toarray()\n",
    "# oov(out of vocabulary) words are handled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745abd5",
   "metadata": {},
   "source": [
    "#### 1.2. Bag of n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e73fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-gram\n",
    "cv2=CountVectorizer(ngram_range=(2,2))\n",
    "bow2=cv2.fit_transform(df1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65f8f97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people watch': 2, 'watch campusx': 4, 'campusx watch': 0, 'people write': 3, 'write comment': 5, 'campusx write': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cv2.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "318c6d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 1 0]]\n",
      "[[1 0 0 0 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bow2[0].toarray())\n",
    "print(bow2[1].toarray())\n",
    "cv2.transform(['campusx watch and write comment of campusx']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49c2fa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-gram + tri-gram +uni-gram\n",
    "cv3=CountVectorizer(ngram_range=(1,3))\n",
    "bow3=cv3.fit_transform(df1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70a2ba5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 6, 'watch': 11, 'campusx': 0, 'people watch': 7, 'watch campusx': 12, 'people watch campusx': 8, 'campusx watch': 1, 'campusx watch campusx': 2, 'write': 13, 'comment': 5, 'people write': 9, 'write comment': 14, 'people write comment': 10, 'campusx write': 3, 'campusx write comment': 4}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(cv3.vocabulary_)\n",
    "print(len(cv3.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e8d9e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 1 1 1 0 0 1 1 0 0]]\n",
      "[[2 1 1 0 0 0 0 0 0 0 0 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow3[0].toarray())\n",
    "print(bow3[1].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca4c94e",
   "metadata": {},
   "source": [
    "## 2. Tf-Idf (Term frequency - Inverse document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2603562d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49681612, 0.        , 0.61366674, 0.61366674, 0.        ],\n",
       "       [0.8508161 , 0.        , 0.        , 0.52546357, 0.        ],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.        , 0.57735027],\n",
       "       [0.49681612, 0.61366674, 0.        , 0.        , 0.61366674]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()\n",
    "tfidf.fit_transform(df1['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89935c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22314355 1.51082562 1.51082562 1.51082562 1.51082562]\n",
      "['campusx' 'comment' 'people' 'watch' 'write']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.idf_)\n",
    "print(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed6c51",
   "metadata": {},
   "source": [
    "## 3. Ohe (One hot encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b11881",
   "metadata": {},
   "source": [
    "#### Without using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782afcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['people', 'watch', 'campusx', 'write', 'comment']\n"
     ]
    }
   ],
   "source": [
    "vocab=[]\n",
    "for i in range(len(df1['text'])):\n",
    "    for word in df1['text'][i].split():\n",
    "        if word in vocab:\n",
    "            continue\n",
    "        else:\n",
    "            vocab.append(word)\n",
    "print (vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0af517a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   campusx  comment  people  watch  write\n",
      "0        0        0       1      0      0\n",
      "1        0        0       0      1      0\n",
      "2        1        0       0      0      0\n",
      "3        0        0       0      0      1\n",
      "4        0        1       0      0      0\n"
     ]
    }
   ],
   "source": [
    "df_encoded = pd.get_dummies(vocab, dtype=int)\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46ba350f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(df_encoded['campusx'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b82041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=[]\n",
    "def ohe (text):\n",
    "    for word in text.split():\n",
    "       arr.append(df_encoded[word].to_numpy()) \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ecc8eaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0...\n",
       "1    [[1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0...\n",
       "2    [[1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0...\n",
       "3    [[1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['text'].apply(ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104e12f5",
   "metadata": {},
   "source": [
    "#### Using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84d6ea2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "['words_0' 'words_1' 'words_2' 'words_3' 'words_4' 'words_5']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Sample sentences\n",
    "sentences = [\"This is the first sentence.\", \"This is the second sentence.\"]\n",
    "\n",
    "# Tokenize and create vocabulary\n",
    "words = \" \".join(sentences).split()\n",
    "unique_words = list(set(words))\n",
    "\n",
    "# Create word-to-index mapping\n",
    "word_to_index = {word: index for index, word in enumerate(unique_words)}\n",
    "\n",
    "# Convert sentences to numerical representations\n",
    "numerical_sentences = [[word_to_index[word] for word in sentence.split()] for sentence in sentences]\n",
    "\n",
    "# One-hot encode the sentences\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_sentences = ohe.fit_transform(np.array(numerical_sentences).reshape(-1, 1))\n",
    "\n",
    "# Print the encoded sentences\n",
    "print(encoded_sentences)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = ohe.get_feature_names_out(['words'])\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105a155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
