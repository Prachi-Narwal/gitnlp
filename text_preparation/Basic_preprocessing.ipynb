{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ab591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f42469c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'F:\\NLP\\IMDB Dataset.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb216ae",
   "metadata": {},
   "source": [
    "## 1. Lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d13caac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i've seen lonesome dove, dead man's walk, and the streets of laredo, and now the return to lonesome dove. if you are hungry for more after watching lonesome dove, this'll fill yer belly. great cast, great story. most definitely a close second to lonesome dove. i will be purchasing this movie to add to my collection. this is the best, or at least my favorite performance by jon voight. he is captain call. lou gossett jr. playing isom pickett is not somebody i'd mess with, he is a bad ass with perspective. william peterson does a great job as well. rick schroder is back as newt with an angst filled performance that reminds me of his stint on nypd blue. my only problem with this film (and it's really picking nits) is that i had the impression that call wanted to be \"the first man to graze cattle in montana\", and it's obvious that dunnigan had already been there a while. a little inconsistent, but easily overlooked as you lose yourself in the fantastic tale. i especially love the apparent character growth of jasper fant and july johnson. i've watched this movie several times and am ready for another sequel.\n"
     ]
    }
   ],
   "source": [
    "print(df['review'][41641].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a29953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41287</th>\n",
       "      <td>this has to be the worst movie ever!!! the act...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32400</th>\n",
       "      <td>this is one of those films that i could only s...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668</th>\n",
       "      <td>...here comes the romeo division to change the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "41287  this has to be the worst movie ever!!! the act...  negative\n",
       "32400  this is one of those films that i could only s...  negative\n",
       "7668   ...here comes the romeo division to change the...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']=df['review'].str.lower()\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874630d3",
   "metadata": {},
   "source": [
    "## 2. HTML tag removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08c8e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def strip_html_tags(text):\n",
    "    pattern=re.compile('<.*?>')\n",
    "    return pattern.sub('',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "161237f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in df['review']:\n",
    "#     strip_html_tags(i)\n",
    "df['review']=df['review'].apply(strip_html_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a72059",
   "metadata": {},
   "source": [
    "## 3. URL removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2597d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    pattern=re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "319420b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Text With URL.\n",
    "text1 = 'Check out my notebook https://www.kaggle.com/campusx/notebook8223fc1abb'\n",
    "text2 = 'Check out my notebook http://www.kaggle.com/campusx/notebook8223fc1abb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba8d76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check out my notebook \n",
      "Check out my notebook \n"
     ]
    }
   ],
   "source": [
    "print(remove_URL(text1))\n",
    "print(remove_URL(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca36c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63366b5f",
   "metadata": {},
   "source": [
    "## 4.Punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac55bb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string,time\n",
    "punc=string.punctuation\n",
    "print(punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51e1ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in punc:\n",
    "        text=text.replace(char,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5207ddf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola Tu hablas Español\n",
      "                                                  review sentiment\n",
      "38013  although written by stephen king an overrated ...  positive\n",
      "33348  im absolutely disgusted this movie isnt being ...  positive\n",
      "33969  retro puppet master is complete and utter crap...  negative\n",
      "1.3670952320098877 1744796207.5028598\n"
     ]
    }
   ],
   "source": [
    "sample_text='Hola! Tu hablas Español?'\n",
    "start=time.time()\n",
    "print(remove_punc(sample_text))\n",
    "df['review']=df['review'].apply(remove_punc)\n",
    "print(df.sample(3))\n",
    "time1=time.time()-start\n",
    "print(time1, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e74d9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_punc(text):\n",
    "    return text.translate(str.maketrans('','',punc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "399bc4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola Tu hablas Español\n",
      "                                                  review sentiment\n",
      "45353  paranormal state is an interesting show for mo...  negative\n",
      "38026  french cinema sucks down with all these psychi...  negative\n",
      "15099  the production values for this film make it fa...  negative\n",
      "1.1895554065704346 1744796210.1858432\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(remove_punc(sample_text))\n",
    "df['review']=df['review'].apply(remove_punc)\n",
    "print(df.sample(3))\n",
    "time2=time.time()-start\n",
    "print(time2, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5b14425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1492488911897867\n"
     ]
    }
   ],
   "source": [
    "print(time1/time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905cdd8f",
   "metadata": {},
   "source": [
    "## 5. ChatWords handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef2b302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here Come ChatWords from a Github Repository\n",
    "# Repository Link : https://github.com/rishabhverma17/sms_slang_translator/blob/master/slang.txt\n",
    "chat_words = {\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"AFK\": \"Away From Keyboard\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"ATK\": \"At The Keyboard\",\n",
    "    \"ATM\": \"At The Moment\",\n",
    "    \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
    "    \"BAK\": \"Back At Keyboard\",\n",
    "    \"BBL\": \"Be Back Later\",\n",
    "    \"BBS\": \"Be Back Soon\",\n",
    "    \"BFN\": \"Bye For Now\",\n",
    "    \"B4N\": \"Bye For Now\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BRT\": \"Be Right There\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"B4\": \"Before\",\n",
    "    \"B4N\": \"Bye For Now\",\n",
    "    \"CU\": \"See You\",\n",
    "    \"CUL8R\": \"See You Later\",\n",
    "    \"CYA\": \"See You\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"FC\": \"Fingers Crossed\",\n",
    "    \"FWIW\": \"For What It's Worth\",\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"GAL\": \"Get A Life\",\n",
    "    \"GG\": \"Good Game\",\n",
    "    \"GN\": \"Good Night\",\n",
    "    \"GMTA\": \"Great Minds Think Alike\",\n",
    "    \"GR8\": \"Great!\",\n",
    "    \"G9\": \"Genius\",\n",
    "    \"IC\": \"I See\",\n",
    "    \"ICQ\": \"I Seek you (also a chat program)\",\n",
    "    \"ILU\": \"ILU: I Love You\",\n",
    "    \"IMHO\": \"In My Honest/Humble Opinion\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"IOW\": \"In Other Words\",\n",
    "    \"IRL\": \"In Real Life\",\n",
    "    \"KISS\": \"Keep It Simple, Stupid\",\n",
    "    \"LDR\": \"Long Distance Relationship\",\n",
    "    \"LMAO\": \"Laugh My A.. Off\",\n",
    "    \"LOL\": \"Laughing Out Loud\",\n",
    "    \"LTNS\": \"Long Time No See\",\n",
    "    \"L8R\": \"Later\",\n",
    "    \"MTE\": \"My Thoughts Exactly\",\n",
    "    \"M8\": \"Mate\",\n",
    "    \"NRN\": \"No Reply Necessary\",\n",
    "    \"OIC\": \"Oh I See\",\n",
    "    \"PITA\": \"Pain In The A..\",\n",
    "    \"PRT\": \"Party\",\n",
    "    \"PRW\": \"Parents Are Watching\",\n",
    "    \"QPSA?\": \"Que Pasa?\",\n",
    "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
    "    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
    "    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n",
    "    \"SK8\": \"Skate\",\n",
    "    \"STATS\": \"Your sex and age\",\n",
    "    \"ASL\": \"Age, Sex, Location\",\n",
    "    \"THX\": \"Thank You\",\n",
    "    \"TTFN\": \"Ta-Ta For Now!\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"U\": \"You\",\n",
    "    \"U2\": \"You Too\",\n",
    "    \"U4E\": \"Yours For Ever\",\n",
    "    \"WB\": \"Welcome Back\",\n",
    "    \"WTF\": \"What The F...\",\n",
    "    \"WTG\": \"Way To Go!\",\n",
    "    \"WUF\": \"Where Are You From?\",\n",
    "    \"W8\": \"Wait...\",\n",
    "    \"7K\": \"Sick:-D Laugher\",\n",
    "    \"TFW\": \"That feeling when\",\n",
    "    \"MFW\": \"My face when\",\n",
    "    \"MRW\": \"My reaction when\",\n",
    "    \"IFYP\": \"I feel your pain\",\n",
    "    \"TNTL\": \"Trying not to laugh\",\n",
    "    \"JK\": \"Just kidding\",\n",
    "    \"IDC\": \"I don't care\",\n",
    "    \"ILY\": \"I love you\",\n",
    "    \"IMU\": \"I miss you\",\n",
    "    \"ADIH\": \"Another day in hell\",\n",
    "    \"ZZZ\": \"Sleeping, bored, tired\",\n",
    "    \"WYWH\": \"Wish you were here\",\n",
    "    \"TIME\": \"Tears in my eyes\",\n",
    "    \"BAE\": \"Before anyone else\",\n",
    "    \"FIMH\": \"Forever in my heart\",\n",
    "    \"BSAAW\": \"Big smile and a wink\",\n",
    "    \"BWL\": \"Bursting with laughter\",\n",
    "    \"BFF\": \"Best friends forever\",\n",
    "    \"CSL\": \"Can't stop laughing\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8727446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_chatwords(text):\n",
    "    new_text=[]\n",
    "    for i in text.split():\n",
    "        if i.upper() in chat_words:\n",
    "            new_text.append(chat_words[i.upper()])\n",
    "        else:\n",
    "            new_text.append(i)\n",
    "    return ' '.join(new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "787ad6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In My Honest/Humble Opinion he is the best\n"
     ]
    }
   ],
   "source": [
    "text = 'IMHO he is the best'\n",
    "print(convert_chatwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aabe0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(convert_chatwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79dec93",
   "metadata": {},
   "source": [
    "## 6. Spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0d67663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is a good person\n",
      "<class 'textblob.blob.TextBlob'>\n",
      "He is a good person\n",
      "<class 'str'>\n",
      "He is a good person\n"
     ]
    }
   ],
   "source": [
    "text='He ys a goood prson'\n",
    "from textblob import TextBlob\n",
    "textblb=TextBlob(text)\n",
    "print(textblb.correct())\n",
    "print(type(textblb.correct()))\n",
    "print(textblb.correct().string)\n",
    "print(type(textblb.correct().string))\n",
    "text=textblb.correct().string\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "460f1ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'person']\n"
     ]
    }
   ],
   "source": [
    "a=['goood','prson']\n",
    "for i in range(len(a)):\n",
    "    textblb=TextBlob(a[i])\n",
    "    a[i]=textblb.correct().string\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8050f351",
   "metadata": {},
   "source": [
    "## 7. Stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0db667af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopword=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0a7cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwrds(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in stopword:\n",
    "            continue\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8cf6c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text With Stop Words :probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it's not preachy or boring. it just never gets old, despite my having seen it some 15 or more times\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'probably all-time favorite movie, story selflessness, sacrifice dedication noble cause, preachy boring. never gets old, despite seen 15 times'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it\\'s not preachy or boring. it just never gets old, despite my having seen it some 15 or more times'\n",
    "print(f'Text With Stop Words :{text}')\n",
    "# Calling Function\n",
    "remove_stopwrds(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b69c78fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>movie potential really good considering plot e...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14453</th>\n",
       "      <td>rented creep impressed didnt feel anything fil...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>one horror movie based tv show gets right frid...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "2151   movie potential really good considering plot e...  negative\n",
       "14453  rented creep impressed didnt feel anything fil...  negative\n",
       "7062   one horror movie based tv show gets right frid...  positive"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']=df['review'].apply(remove_stopwrds)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a514660e",
   "metadata": {},
   "source": [
    "## 8. Handling emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e90037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68b5c27d",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b7fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I like to eat Guava, grapes.\n",
      "Meena's friends also like Guava.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "corpus=\"\"\"Hello! I like to eat Guava, grapes.\n",
    "Meena's friends also like Guava.\n",
    "\"\"\"\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "407152d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello!', 'I like to eat Guava, grapes.', \"Meena's friends also like Guava.\"]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "# Paragraph --> sentences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "documents=sent_tokenize(corpus)\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19773402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "I like to eat Guava, grapes.\n",
      "Meena's friends also like Guava.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "  print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cfe6f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '!', 'I', 'like', 'to', 'eat', 'Guava', ',', 'grapes', '.', 'Meena', \"'s\", 'friends', 'also', 'like', 'Guava', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "# paragraph --> words\n",
    "\n",
    "from nltk.tokenize import word_tokenize   # 's is taken as one\n",
    "words=word_tokenize(corpus)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597aede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '!']\n",
      "['I', 'like', 'to', 'eat', 'Guava', ',', 'grapes', '.']\n",
      "['Meena', \"'s\", 'friends', 'also', 'like', 'Guava', '.']\n"
     ]
    }
   ],
   "source": [
    "# sentence --> words\n",
    "for sentence in documents:\n",
    "  print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b76c6f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '!', 'I', 'like', 'to', 'eat', 'Guava', ',', 'grapes', '.', 'Meena', \"'\", 's', 'friends', 'also', 'like', 'Guava', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import wordpunct_tokenize # 's is taken as 2 tokens\n",
    "print(wordpunct_tokenize(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "749d5418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '!', 'I', 'like', 'to', 'eat', 'Guava', ',', 'grapes.', 'Meena', \"'s\", 'friends', 'also', 'like', 'Guava', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import TreebankWordTokenizer  # . is not treated separately, only last . is treated seprately\n",
    "tokenizer=TreebankWordTokenizer()  # it is a class\n",
    "print(tokenizer.tokenize(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecac9618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
